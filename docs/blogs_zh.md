---
name: context-engineering-blogs
description: 关于上下文工程的技术博客合集，涵盖了代助手系统中管理上下文窗口的策略，包括写入、选择、压缩和隔离模式。
doc_type: blog
source_url: No
---

我最近读到并认为非常有价值的一些技术博客：

# 上下文工程 (Context Engineering)

11 分钟阅读 | 2025 年 7 月 2 日

**TL;DR**
助手需要上下文来执行任务。上下文工程是在助手运行的每一步中，用恰到好处的信息填充上下文窗口的艺术与科学。在本文中，通过回顾各种流行的助手和论文，我们分解了一些常见的上下文工程策略：写入、选择、压缩和隔离。然后，我们解释了 LangGraph 是如何设计来支持这些策略的！

[链接至上下文工程视频]

## 上下文工程的一般类别

正如 Andrej Karpathy 所言，LLM 就像是一种新型的操作系。LLM 是 CPU，而它的上下文窗口就是 RAM，充当模型的工作记忆。就像 RAM 一样，LLM 上下文窗口处理各种来源上下文的能力有限。正如同操作系统策划什么内容进入 CPU 的 RAM 一样，我们可以认为“上下文工程”扮演着类似的角色。Karpathy 很好地总结了这一点：

> “[上下文工程是]……在每一步中，用恰到好处的信息填充上下文窗口的精妙艺术与科学。”

### 构建 LLM 应用时常用的上下文类型

在构建 LLM 应用时，我们需要管理哪些类型的上下文？上下文工程是一个涵盖了几种不同上下文类型的伞状概念：
- **指令** – 提示词、记忆、少样本示例、工具描述等
- **知识** – 事实、记忆等
- **工具** – 来自工具调用的反馈

## 助手的上下文工程

今年，随着 LLM 在推理和工具调用方面表现得越来越好，对助手的兴趣也呈爆炸式增长。助手将 LLM 调用和工具调用交织在一起，通常用于长时间运行的任务。

然而，长时间运行的任务和从工具调用中不断累积的反馈意味着助手通常会消耗大量的 token。这会导致许多问题：可能超过上下文窗口的大小、成本/延迟激增，或者助手性能下降。Drew Breunig 很好地总结了长上下文可能导致性能问题的几种具体方式，包括：
- **上下文毒化 (Context Poisoning)**：当幻觉进入上下文时
- **上下文干扰 (Context Distraction)**：当上下文压倒了训练内容时
- **上下文混淆 (Context Confusion)**：当多余的上下文影响了回复时
- **上下文冲突 (Context Clash)**：当上下文的不同部分相互矛盾时

考虑到这一点，Cognition 指出了上下文工程的重要性：
> “‘上下文工程’……实际上是构建 AI 助手的人员的首要任务。”

Anthropic 也明确表示：
> “助手通常参与跨越数百轮的对话，需要仔细的上下文管理策略。”

那么，人们今天是如何应对这一挑战的呢？我们通过回顾流行的助手产品和论文，将常见的助手上下文工程策略归纳为四个桶：**写入、选择、压缩和隔离**。

---

## 1. 写入上下文 (Write Context)
写入上下文意味着将其保存在上下文窗口之外，以帮助助手执行任务。

### 临时记事板 (Scratchpads)
当人类解决任务时，我们会做笔记并记住与未来相关任务相关的事情。助手也正在获得这些能力！通过“记事板”进行笔记记录是在助手执行任务期间持久化信息的一种方法。其核心思想是将信息保存在上下文窗口之外，以便供助手使用。Anthropic 的多代理研究人员展示了一个清晰的例子：
> LeadResearcher 首先思考方法并将计划保存到 Memory（记忆）中以持久化上下文，因为如果上下文窗口超过 200,000 个 token，它将被截断，保留计划至关重要。

记事板可以通过几种不同的方式实现：
- 只是简单地写入文件的工具调用。
- 也可以是会话期间持久存在的运行时状态对象中的一个字段。

### 记忆 (Memories)
记事板帮助助手在给定的会话（或线程）内解决任务，但有时助手能从跨多个会话的记忆中受益！Reflexion 引入了在每个助手步骤后进行反思并重新使用这些自我生成的记忆的想法。Generative Agents 创建了定期从过去助手反馈集合中综合而成的记忆。

这些概念已进入 ChatGPT、Cursor 和 Windsurf 等流行产品，它们都有根据用户与助手交互自动生成可跨会话持久存在的长期记忆的机制。

---

## 2. 选择上下文 (Select Context)
选择上下文意味着将其拉入上下文窗口，以帮助助手执行任务。

### 记事板
从记事板中选择上下文的机制取决于记事板是如何实现的。如果它是工具，助手只需通过工具调用来读取它。如果它是助手运行时状态的一部分，则开发人员可以决定在每一步中将状态的哪些部分暴露给助手。这为在后续步骤中向 LLM 暴露记事板上下文提供了精细的控制。

### 记忆
如果助手有保存记忆的能力，他们也需要选择与正在执行的任务相关的记忆的能力。这可能很有用：助手可能会选择少样本示例（情景记忆）作为期望行为的示例、指令（程序性记忆）来引导行为，或事实（语义记忆）作为任务相关的上下文。

一个挑战是确保选择了相关的记忆。一些流行的助手只是简单地使用一组始终拉入上下文的特定文件。例如，许多代码助手使用特定文件来保存指令（“程序性”记忆），或在某些情况下保存示例（“情景”记忆）。Claude Code 使用 `CLAUDE.md`。Cursor 和 Windsurf 使用规则文件。

但是，如果助手存储了大量的事实和/或关系（例如语义记忆），选择就更难了。索引通常用于辅助选择。Simon Willison 在 AIEngineer World’s Fair 上分享了一个选择出错的例子：ChatGPT 从记忆中抓取了他的位置，并出乎意料地将其注入到了请求生成的图像中。

### 工具
助手使用工具，但如果提供太多工具可能会过载。这通常是因为工具描述重叠，导致模型对使用哪个工具感到困惑。一种方法是对工具描述应用 RAG（检索增强生成），以便仅获取任务最相关的工具。

### 知识
RAG 是一个丰富的主题，可能是一个核心的上下文工程挑战。Varun (Windsurf) 总结道：代码的索引不等于上下文检索。随着代码库规模的增长，嵌入搜索作为检索启发式方法变得不可靠，必须结合 grep/文件搜索、基于知识图谱的检索和重排序步骤。

---

## 3. 压缩上下文 (Compressing Context)
压缩上下文涉及仅保留执行任务所需的 token。

### 上下文摘要 (Context Summarization)
助手交互可能跨越数百轮并消耗大量 token。摘要是应对这些挑战的常用方法。如果您使用过 Claude Code，您就会看到这一点。当您超过上下文窗口的 95% 时，Claude Code 会运行“自动压缩”，它会摘要用户与助手交互的完整轨迹。

在助手的某些设计点添加摘要也很有用。例如，它可以用于后处理某些工具调用（如搜索工具）。或者用于在助手之间的边界减少知识移交时的 token。

### 上下文修剪 (Context Trimming)
摘要通常使用 LLM 来提炼最相关的上下文，而修剪通常可以直接过滤或“剪枝”上下文。这可以使用硬编码的启发式方法，例如从列表中删除旧消息。

---

## 4. 隔离上下文 (Isolating Context)
隔离上下文涉及将其拆分以帮助助手执行任务。

### 多助手 (Multi-agent)
隔离上下文最流行的方法之一是跨子助手拆分。OpenAI Swarm 库的一个动机是关注点分离，一个助手团队可以处理特定的子任务。每个助手都有特定的一组工具、指令和自己的上下文窗口。

Anthropic 的多代理研究人员认为：许多具有隔离上下文的助手优于单助手，主要是因为每个子助手的上下文窗口可以分配给更狭窄的子任务。

当然，多助手的挑战包括 token 使用量激增（Anthropic 报告的消耗量比聊天高出 15 倍）、需要精细的提示词工程来规划子助手的工作，以及子助手的协调。

### 环境中的上下文隔离
HuggingFace 的 deep researcher 展示了另一个有趣的上下文隔离示例。它使用 `CodeAgent` 在沙盒中运行代码。来自工具调用的所选上下文（如返回值）随后被传回 LLM。这允许将消耗 token 巨大的对象隔离在 LLM 的环境之外。

### 状态 (State)
助手的运行时状态对象也是隔离上下文的好方法。模式可以设计为具有可写入上下文的字段。模式的一个字段（如消息）可以每轮暴露给 LLM，而其他字段则隔离信息。

---

# 使用 LangSmith / LangGraph 进行上下文工程

LangGraph 旨在提供线程范围内（短期）和长期记忆。短期记忆允许您将信息写入状态并在轨迹的任何步骤抓取。LangMem 提供了一组广泛的抽象来辅助 LangGraph 的记忆管理。

在 LangGraph 助手的每个节点（步骤）中，您都可以获取状态。这让您能够微调在每个步骤中向 LLM 展示的上下文。

对于工具选择，LangGraph 的 Bigtool 库是对工具描述应用语义搜索的好方法。

在压缩上下文方面，由于 LangGraph 是一个底层编排框架，您将助手布局为一组节点，您可以添加逻辑来后处理工具调用或在特定点添加摘要节点。

---

# Manus 中的上下文工程

2025 年 10 月 15 日 | Lance Martin

Manus 任务平均使用 50 次工具调用。如果没有上下文工程，这些工具调用结果会在上下文窗口中累积并导致性能退化。Karpathy 明确说道：上下文工程是在助手的轨迹中，用恰到好处的信息填充上下文窗口的精妙艺术与科学。

Manus 采用三种主要策略：**减少上下文、分流上下文和隔离上下文**。

## 1. 减少上下文
工具调用有“完整”和“精简”两种表示。完整版保存在沙盒（文件系统）中，精简版保存对结果的引用（如文件路径）。Manus 对陈旧的工具结果应用压缩，将其替换为精简版。当压缩达到收益递减时，Manus 对轨迹应用基于 Schema 的摘要。

## 2. 隔离上下文
Manus 使用子助手的首要目标是隔离上下文。例如，Manus 会将一个任务分配给一个拥有自己上下文窗口的子助手。Manus 包含一个规划器（Planner）、一个知识管理器和一个执行器子助手。

## 3. 分流上下文
工具描述占用宝贵的 token。Manus 通过在沙盒层（其虚拟计算机）直接运行许多实用程序来分流大部分操作。Manus 使用一小组原子函数（< 20 个），包括 Bash 工具、文件系统管理工具等。大部分动作通过 Bash 工具在沙盒中执行。

---

# 为 AI 助手编写有效工具 —— 与助手协作

2025 年 9 月 11 日

工具是确定性系统和非确定性助手之间的一种新契约。为助手设计工具需要从根本上重新思考：不是像为开发人员写 API 那样，而是专门为助手设计。

## 如何编写工具
我们的流程是：快速原型制作 -> 运行全面评估 -> 与助手协作优化。

### 运行评估
通过运行评估来衡量 Claude 使用工具的情况。基于现实世界用途生成大量评估任务。一个好的指标不应仅仅是准确率，还应包括运行时间、工具调用次数、token 消耗和错误率。

## 编写高质量工具的关键原则
- 选择合适的工具来开发。
- 命名空间化工具以定义清晰的功能边界。
- 从工具向助手返回有意义的内容。
- 优化工具响应的 token 效率。
- 为工具描述和规范进行提示词工程。
