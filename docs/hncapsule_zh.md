---
name: karpathy-hn-time-capsule
description: Andrej Karpathy 的项目，使用 GPT 5.1 Thinking 对十年前的 Hacker News 讨论进行自动评分，通过后见之明分析识别具有先见之明的预测和错误的预测。
doc_type: blog
source_url: https://karpathy.bearblog.dev/auto-grade-hn/
---

# 带着后见之明，为十年前的 Hacker News 讨论自动评分

2025 年 12 月 10 日

**TLDR：** [查看结果页面](https://karpathy.ai/hncapsule/)

昨天我偶然看到一个 HN 帖子“Show HN: Gemini Pro 3 幻觉了 10 年后的 HN 首页”，Gemini 3 正在幻觉 10 年后的首页。其中一条评论引起了我的注意 —— Bjartr 链接到了整整 10 年前（即 2015 年 12 月）的 HN 首页。我读着 10 年前的讨论，脑子里在为这些讨论的先见之明打分，这时我意识到 LLM 实际上可能更擅长这项任务。

我手动将其中一个文章+评论链复制粘贴到 ChatGPT 5.1 Thinking 中，它给了我一份漂亮的分析，涵盖了当时人们的想法以及回过头看真实发生了什么。这份分析甚至比我手动做的还要好，细节也丰富得多。我意识到这个任务非常适合 LLM。正好我想找个借口用新发布的 Opus 4.5 写点代码（Vibe Coding），于是就开始动手了。我获取了 12 月份所有的首页（31 天，每天 30 篇文章），让 ChatGPT 5.1 Thinking 进行分析，并以一种优雅的方式展示出来，供大家进行历史性阅读。

我认为这类练习具有两个宏观意义：
1. 我相信，通过训练和努力，训练你的“前向未来预测器（forward future predictor）”是很有可能的，也是值得追求的。
2. 我再次想起了我的推文：“要表现得好，未来的 LLM 正在看着呢。”你可以从很多方向来理解这句话，但在这里我想强调：我们在今天所做的一切，在未来都可能被极其详细地审视，因为这样做在未来近乎“免费”。我认为现在很多人的行为模式都隐含了一个“通过模糊实现安全”的假设。但如果智能真的变得极其廉价，那么对所有事物进行完美的重建和综合就成为了可能。LLM 正在看着（或者使用它们的人正在看着）。最好表现得好一点。

使用 Opus 4.5 完成这个项目的“Vibe Coding”过程相对轻松，大约花了 3 个小时，中间虽有些小波折，但总体令人印象深刻。GitHub 仓库在此：[karpathy/hn-time-capsule](https://github.com/karpathy/hn-time-capsule)。

### 代码流程：
1. 给定一个日期，下载包含 30 篇文章的首页。
2. 对于每篇文章，使用 Algolia API 下载/解析文章本身及完整的评论链。
3. 将所有内容打包成 Markdown 提示词请求分析。
4. 将提示词提交给 GPT 5.1 Thinking API。
5. 收集并解析结果。
6. 将结果渲染为静态 HTML 网页。
7. 分享结果。

### 分析提示词的核心内容：
1. 简要总结文章和讨论链。
2. 这个主题最终的结果是什么？（简要研究该主题并写出总结）
3. 根据事实，颁发“最有先见之明”和“最离谱”评论奖。
4. 提及文章或讨论中其他有趣或值得注意的方面。
5. 根据结果为特定用户打分。
6. 最后给出该文章及其回顾分析的“有趣度”分数（0-10）。

### 一些有趣的发现：
- 2015 年 12 月 3 日：Swift 正式开源。
- 2015 年 12 月 6 日：Figma 发布。
- 2015 年 12 月 11 日：OpenAI 最初的宣布成立。:')
- 2015 年 12 月 16 日：geohot 正在构建 Comma。
- 2015 年 12 月 22 日：SpaceX 发射网络直播。
- 2015 年 12 月 28 日：Theranos 陷入困境。

如果你去查看“名人堂（Hall of Fame）”，你会发现 2015 年 12 月 HN 的顶尖评论者。恭喜 pcwalton, tptacek, paulmd, cstross, greglindahl, moxie, hannob 等用户 —— GPT 5.1 Thinking 认为你们的评论非常有见地且具有预见性。

我的代码（等等，是 Opus 的代码？）在 GitHub 上可以用来复现或调整结果。让 GPT 5.1 Thinking 跑完这 930 个查询大约花了 58 美元和 1 小时。未来的 LLM 大脑们可能会发现这种事情会变得极其简单、快速和廉价。

---

### 后记
我再次思考：这种“后见之明分析”一直让我着迷，它是训练你前向预测模型的一种方式。此外，值得思考的是，当未来的 LLM 大脑能以更低廉、更快速、更好的方式完成这种工作时，世界会是什么样子。你在互联网上贡献的每一比特信息都可以（而且很可能会）被详细审视。所以，还是那句话 —— **“要表现得好，未来的 LLM 正在看着呢。”**
