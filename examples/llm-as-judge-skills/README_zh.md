# LLM-as-a-Judge æŠ€èƒ½ (LLM-as-a-Judge Skills)

> åŸºäº [Eugene Yan å…³äº LLM-Evaluators çš„ç ”ç©¶](https://eugeneyan.com/writing/llm-evaluators/) å’Œ [Vercel AI SDK 6](https://vercel.com/blog/ai-sdk-6) çš„è§è§£æ„å»ºçš„ LLM è¯„ä¼°æŠ€èƒ½çš„å®è·µå®ç°ã€‚

[![è®¸å¯è¯: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.6-blue.svg)](https://www.typescriptlang.org/)
[![AI SDK](https://img.shields.io/badge/AI%20SDK-4.1-green.svg)](https://sdk.vercel.ai/)
[![æµ‹è¯•](https://img.shields.io/badge/Tests-19%20passed-brightgreen.svg)](#æµ‹è¯•ç»“æœ)

## ğŸ¯ ç›®çš„

æœ¬ä»“åº“å±•ç¤ºäº†å¦‚ä½•æ„å»º**ç”Ÿäº§çº§ LLM è¯„ä¼°æŠ€èƒ½**ï¼Œä½œä¸º [Agent Skills for Context Engineering](https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering) é¡¹ç›®çš„ä¸€éƒ¨åˆ†ã€‚å®ƒä½œä¸ºä¸€ä¸ªå®è·µç¤ºä¾‹ï¼Œå±•ç¤ºäº†ï¼š

1. **æŠ€èƒ½å¼€å‘**ï¼šå¦‚ä½•å°†ç ”ç©¶è§è§£è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„åŠ©æ‰‹æŠ€èƒ½ã€‚
2. **å·¥å…·è®¾è®¡**ï¼šæ„å»ºå…·æœ‰æ­£ç¡® Schema å’Œé”™è¯¯å¤„ç†æœºåˆ¶çš„ AI å·¥å…·çš„æœ€ä½³å®è·µã€‚
3. **è¯„ä¼°æ¨¡å¼**ï¼šç”¨äºè´¨é‡è¯„ä¼°çš„ LLM-as-a-Judge æ¨¡å¼çš„å®ç°ã€‚

### ä¸Šä¸‹æ–‡å·¥ç¨‹ç”Ÿæ€ç³»ç»Ÿçš„ä¸€éƒ¨åˆ†

æ­¤é¡¹ç›®æ˜¯ä¸€ä¸ªç¤ºä¾‹å®ç°ï¼Œæ—¨åœ¨æ·»åŠ åˆ°ï¼š
- ğŸ“ [`Agent-Skills-for-Context-Engineering/examples/`](https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering/tree/main/examples)

å®ƒå»ºç«‹åœ¨ä»¥ä¸‹åŸºç¡€æŠ€èƒ½ä¹‹ä¸Šï¼š
- ğŸ“š [`skills/context-fundamentals`](../../skills/context-fundamentals/SKILL_zh.md) - ä¸Šä¸‹æ–‡å·¥ç¨‹åŸåˆ™
- ğŸ”§ [`skills/tool-design`](../../skills/tool-design/SKILL_zh.md) - å·¥å…·è®¾è®¡æœ€ä½³å®è·µ

---

## ğŸ“– èƒŒæ™¯ä¸ç ”ç©¶

### LLM-as-a-Judge é—®é¢˜

è¯„ä¼° AI ç”Ÿæˆçš„å†…å®¹æå…·æŒ‘æˆ˜æ€§ã€‚ä¼ ç»Ÿçš„æŒ‡æ ‡ï¼ˆBLEU, ROUGEï¼‰å¾€å¾€ä¼šå¿½ç•¥é‡è¦çš„ç»†å¾®å·®åˆ«ã€‚Eugene Yan å…³äº [LLM-Evaluators](https://eugeneyan.com/writing/llm-evaluators/) çš„ç ”ç©¶ç¡®å®šäº†ä½¿ç”¨ LLM æ¥åˆ¤æ–­ LLM è¾“å‡ºçš„æœ‰æ•ˆæ¨¡å¼ã€‚

**æˆ‘ä»¬å®ç°çš„çš„å…³é”®è§è§£ï¼š**

| è§è§£ | å®ç°æ–¹æ¡ˆ |
|---------|----------------|
| ç›´æ¥è¯„åˆ†æœ€é€‚åˆå®¢è§‚æ ‡å‡† | å…·æœ‰è¯„åˆ†æ ‡å‡†æ”¯æŒçš„ `directScore` å·¥å…· |
| æˆå¯¹æ¯”è¾ƒå¯¹äºåå¥½è¯„ä¼°æ›´å¯é  | å…·æœ‰ä½ç½®äº¤æ¢åŠŸèƒ½çš„ `pairwiseCompare` å·¥å…· |
| ä½ç½®åå·®ä¼šå½±å“æˆå¯¹åˆ¤æ–­ | åœ¨æ¯”è¾ƒä¸­è‡ªåŠ¨è¿›è¡Œä½ç½®äº¤æ¢ |
| æ€ç»´é“¾ï¼ˆCoTï¼‰æé«˜å¯é æ€§ | æ‰€æœ‰è¯„ä¼°éƒ½éœ€è¦æä¾›åŸºäºè¯æ®çš„ç†ç”± |
| æ¸…æ™°çš„è¯„åˆ†æ ‡å‡†å¯å‡å°‘æ–¹å·® | ç”¨äºå»ºç«‹ä¸€è‡´æ ‡å‡†çš„ `generateRubric` å·¥å…· |

### Vercel AI SDK 6 æ¨¡å¼

æˆ‘ä»¬åˆ©ç”¨äº† AI SDK 6 çš„æ–°æ¨¡å¼ï¼š

- **æ™ºèƒ½ä½“æŠ½è±¡**ï¼šå…·æœ‰å¤šç§èƒ½åŠ›çš„ã€å¯é‡ç”¨çš„ `EvaluatorAgent` ç±»ã€‚
- **ç±»å‹å®‰å…¨å·¥å…·**ï¼šä¸ºæ‰€æœ‰è¾“å…¥/è¾“å‡ºæä¾› Zod Schemaã€‚
- **ç»“æ„åŒ–è¾“å‡º**ï¼šç»è¿‡è§£æå’ŒéªŒè¯çš„ JSON å“åº”ã€‚
- **é”™è¯¯å¤„ç†**ï¼šå½“ API è°ƒç”¨å¤±è´¥æ—¶ä¼˜é›…é™çº§ã€‚

---

## ğŸ—ï¸ æˆ‘ä»¬æ„å»ºäº†ä»€ä¹ˆ

### æ¶æ„æ¦‚è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        LLM-as-a-Judge æŠ€èƒ½                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    æŠ€èƒ½     â”‚    â”‚   æç¤ºè¯    â”‚    â”‚         å·¥å…·            â”‚  â”‚
â”‚  â”‚  (MD æ–‡æ¡£)  â”‚â”€â”€â”€â–¶â”‚   (æ¨¡æ¿)    â”‚â”€â”€â”€â–¶â”‚  (TypeScript å®ç°)      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                                         â”‚                   â”‚
â”‚         â”‚                                         â–¼                   â”‚
â”‚         â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚    è¯„ä¼°æ™ºèƒ½ä½“           â”‚  â”‚
â”‚                                         â”‚  â”œâ”€â”€ score()            â”‚  â”‚
â”‚                                         â”‚  â”œâ”€â”€ compare()          â”‚  â”‚
â”‚                                         â”‚  â”œâ”€â”€ generateRubric()   â”‚  â”‚
â”‚                                         â”‚  â””â”€â”€ chat()             â”‚  â”‚
â”‚                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                     â”‚                 â”‚
â”‚                                                     â–¼                 â”‚
â”‚                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                                         â”‚   OpenAI GPT-5.2 API     â”‚  â”‚
â”‚                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ç›®å½•ç»“æ„

```
llm-as-judge-skills/
â”œâ”€â”€ skills/                          # åŸºç¡€çŸ¥è¯† (MD æ–‡æ¡£)
â”‚   â”œâ”€â”€ llm-evaluator/               # LLM-as-a-Judge æ¨¡å¼
â”‚   â”‚   â””â”€â”€ llm-evaluator.md         # è¯„ä¼°æ–¹æ³•ã€æŒ‡æ ‡ã€åå·®ç¼“è§£
â”‚   â”œâ”€â”€ context-fundamentals/        # ä¸Šä¸‹æ–‡å·¥ç¨‹åŸåˆ™
â”‚   â”‚   â””â”€â”€ context-fundamentals.md  # æœ‰æ•ˆç®¡ç†ä¸Šä¸‹æ–‡
â”‚   â””â”€â”€ tool-design/                 # å·¥å…·è®¾è®¡æœ€ä½³å®è·µ
â”‚       â””â”€â”€ tool-design.md           # Schema è®¾è®¡ã€é”™è¯¯å¤„ç†
â”‚
â”œâ”€â”€ prompts/                         # æç¤ºè¯æ¨¡æ¿
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ direct-scoring-prompt.md      # è¯„åˆ†æç¤ºè¯æ¨¡æ¿
â”‚   â”‚   â””â”€â”€ pairwise-comparison-prompt.md # æ¯”è¾ƒæç¤ºè¯æ¨¡æ¿
â”‚   â”œâ”€â”€ research/
â”‚   â”‚   â””â”€â”€ research-synthesis-prompt.md
â”‚   â””â”€â”€ agent-system/
â”‚       â””â”€â”€ orchestrator-prompt.md
â”‚
â”œâ”€â”€ tools/                           # å·¥å…·è¯´æ˜æ–‡æ¡£ (MD)
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ direct-score.md          # ç›´æ¥è¯„åˆ†å·¥å…·è§„èŒƒ
â”‚   â”‚   â”œâ”€â”€ pairwise-compare.md      # æˆå¯¹æ¯”è¾ƒè§„èŒƒ
â”‚   â”‚   â””â”€â”€ generate-rubric.md       # è¯„åˆ†æ ‡å‡†ç”Ÿæˆè§„èŒƒ
â”‚   â”œâ”€â”€ research/
â”‚   â”‚   â”œâ”€â”€ web-search.md
â”‚   â”‚   â””â”€â”€ read-url.md
â”‚   â””â”€â”€ orchestration/
â”‚       â””â”€â”€ delegate-to-agent.md
â”‚
â”œâ”€â”€ agents/                          # æ™ºèƒ½ä½“è¯´æ˜æ–‡æ¡£ (MD)
â”‚   â”œâ”€â”€ evaluator-agent/
â”‚   â”‚   â””â”€â”€ evaluator-agent.md
â”‚   â”œâ”€â”€ research-agent/
â”‚   â”‚   â””â”€â”€ research-agent.md
â”‚   â””â”€â”€ orchestrator-agent/
â”‚       â””â”€â”€ orchestrator-agent.md
â”‚
â”œâ”€â”€ src/                             # TypeScript å®ç°ä»£ç 
â”‚   â”œâ”€â”€ tools/evaluation/
â”‚   â”‚   â”œâ”€â”€ direct-score.ts          # 165 è¡Œ - ç›´æ¥è¯„åˆ†å®ç°
â”‚   â”‚   â”œâ”€â”€ pairwise-compare.ts      # 255 è¡Œ - å¸¦æœ‰åå·®ç¼“è§£çš„æˆå¯¹æ¯”è¾ƒ
â”‚   â”‚   â””â”€â”€ generate-rubric.ts       # 162 è¡Œ - è¯„åˆ†æ ‡å‡†ç”Ÿæˆ
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â””â”€â”€ evaluator.ts             # 112 è¡Œ - EvaluatorAgent ç±»
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ index.ts                 # é…ç½®ä¸éªŒè¯
â”‚   â””â”€â”€ index.ts                     # ä¸»å…¥å£
â”‚
â”œâ”€â”€ tests/                           # æµ‹è¯•å¥—ä»¶
â”‚   â”œâ”€â”€ evaluation.test.ts           # å·¥å…·çš„ 9 ä¸ªæµ‹è¯•
â”‚   â”œâ”€â”€ skills.test.ts               # æŠ€èƒ½çš„ 10 ä¸ªæµ‹è¯•
â”‚   â””â”€â”€ setup.ts                     # æµ‹è¯•é…ç½®
â”‚
â””â”€â”€ examples/                        # ä½¿ç”¨ç¤ºä¾‹
    â”œâ”€â”€ basic-evaluation.ts
    â”œâ”€â”€ pairwise-comparison.ts
    â”œâ”€â”€ generate-rubric.ts
    â””â”€â”€ full-evaluation-workflow.ts
```

---

## ğŸ”§ å®ç°çš„æ ¸å¿ƒå·¥å…·

### 1. ç›´æ¥è¯„åˆ†å·¥å…· (`directScore`)

**ç”¨é€”**ï¼šæ ¹æ®å®šä¹‰çš„æ ‡å‡†å¯¹å•ä¸ªå“åº”è¿›è¡Œæ•°å€¼è¯„åˆ†ã€‚

**ä½¿ç”¨åœºæ™¯**ï¼š
- äº‹å®å‡†ç¡®æ€§æ£€æŸ¥
- æŒ‡ä»¤éµå¾ªè¯„ä¼°
- å†…å®¹è´¨é‡åˆ†çº§
- åˆè§„æ€§éªŒè¯

**å®ç°è¦ç‚¹**ï¼š

```typescript
// æºè‡ª src/tools/evaluation/direct-score.ts

const systemPrompt = `ä½ æ˜¯ä¸€ä½ä¸“å®¶è¯„ä¼°å‘˜ã€‚æ ¹æ®æ¯é¡¹æ ‡å‡†è¯„ä¼°å“åº”ã€‚
é’ˆå¯¹æ¯é¡¹æ ‡å‡†ï¼š
1. åœ¨å“åº”ä¸­å¯»æ‰¾å…·ä½“çš„è¯æ®
2. æ ¹æ®è¯„åˆ†æ ‡å‡†æ‰“åˆ†ï¼ˆ1-5 åˆ†åˆ¶ï¼‰
3. é™ˆè¿°è¯„åˆ†ç†ç”±
4. å»ºè®®ä¸€é¡¹æ”¹è¿›

ä¿æŒå®¢è§‚å’Œä¸€è‡´ã€‚æ‰“åˆ†åº”åŸºäºæ˜ç¡®çš„è¯æ®ã€‚`;
```

**å…³é”®ç‰¹æ€§**ï¼š
- æ”¯æŒåŠ æƒæ ‡å‡†
- è¦æ±‚æ€ç»´é“¾ï¼ˆCoTï¼‰ç†ç”±
- ä»å“åº”ä¸­æå–è¯æ®
- é’ˆå¯¹æ¯é¡¹æ ‡å‡†æä¾›æ”¹è¿›å»ºè®®
- å¯é…ç½®è¯„åˆ†æ ‡å‡†ï¼ˆ1-3, 1-5, 1-10 åˆ†åˆ¶ï¼‰

---

### 2. æˆå¯¹æ¯”è¾ƒå·¥å…· (`pairwiseCompare`)

**ç”¨é€”**ï¼šæ¯”è¾ƒä¸¤ä¸ªå“åº”å¹¶ç¡®å®šå“ªä¸ªæ›´å¥½ï¼ŒåŒæ—¶å…·å¤‡ä½ç½®åå·®ç¼“è§£æœºåˆ¶ã€‚

**ä½¿ç”¨åœºæ™¯**ï¼š
- å“åº”çš„ A/B æµ‹è¯•
- åå¥½è¯„ä¼°
- è¯­æ°”å’Œé£æ ¼è¯„ä¼°
- å¯¹è´¨é‡å·®å¼‚è¿›è¡Œæ’åº

**å®ç°è¦ç‚¹**ï¼š

```typescript
// ä½ç½®åå·®ç¼“è§£ï¼šäº¤æ¢ä½ç½®è¿›è¡Œä¸¤æ¬¡è¯„ä¼°
if (input.swapPositions) {
  // ç¬¬ä¸€è½®ï¼šA åœ¨å‰ï¼ŒB åœ¨å
  const pass1 = await evaluatePair(input.responseA, input.responseB, ...);
  
  // ç¬¬äºŒè½®ï¼šB åœ¨å‰ï¼ŒA åœ¨å
  const pass2 = await evaluatePair(input.responseB, input.responseA, ...);
  
  // å°†ç¬¬äºŒè½®çš„ç»“æœæ˜ å°„å› A/B å¹¶æ£€æŸ¥ä¸€è‡´æ€§
  const pass2WinnerMapped = pass2.winner === 'A' ? 'B' : pass2.winner === 'B' ? 'A' : 'TIE';
  const consistent = pass1.winner === pass2WinnerMapped;
  
  // å¦‚æœä¸ä¸€è‡´ï¼Œåˆ™è¿”å›å¹³å±€ (TIE) å¹¶é™ä½ç½®ä¿¡åº¦
  if (!consistent) {
    finalWinner = 'TIE';
    finalConfidence = 0.5;
  }
}
```

**å…³é”®ç‰¹æ€§**ï¼š
- **ä½ç½®äº¤æ¢**ï¼šè‡ªåŠ¨äº¤æ›¿é¡ºåºè¿è¡Œä¸¤æ¬¡è¯„ä¼°ã€‚
- **ä¸€è‡´æ€§æ£€æŸ¥**ï¼šæ£€æµ‹ä½ç½®æ˜¯å¦å½±å“åˆ¤æ–­ã€‚
- **ç½®ä¿¡åº¦è¯„åˆ†**ï¼šåŸºäºä¸€è‡´æ€§çš„ 0-1 ç½®ä¿¡åº¦ã€‚
- **é€é¡¹æ ‡å‡†æ¯”è¾ƒ**ï¼šé’ˆå¯¹æ¯ä¸ªæ–¹é¢çš„è¯¦ç»†æ‹†è§£ã€‚
- **å…·å¤‡åå·®æ„è¯†çš„æç¤ºè¯**ï¼šè¦æ±‚æ¨¡å‹å¿½ç•¥é•¿åº¦å’Œä½ç½®çš„æ˜ç¡®æŒ‡ä»¤ã€‚

---

### 3. è¯„åˆ†æ ‡å‡†ç”Ÿæˆå·¥å…· (`generateRubric`)

**ç”¨é€”**ï¼šä¸ºä¸€è‡´çš„è¯„ä¼°æ ‡å‡†åˆ›å»ºè¯¦ç»†çš„æ‰“åˆ†é‡è¡¨ã€‚

**ä½¿ç”¨åœºæ™¯**ï¼š
- å»ºç«‹è¯„ä¼°æ ‡å‡†
- åŸ¹è®­äººå·¥è¯„ä¼°å‘˜
- ç¡®ä¿è¯„ä¼°çš„ä¸€è‡´æ€§
- è®°å½•è´¨é‡æ ‡å‡†

**å®ç°è¦ç‚¹**ï¼š

```typescript
// ä¸¥æ ¼ç¨‹åº¦å½±å“ç”Ÿæˆçš„è¯„åˆ†æ ‡å‡†ï¼š
// - lenient (å®½æ¾): è¾ƒä½çš„åŠæ ¼é—¨æ§›
// - balanced (å¹³è¡¡): å…¬æ­£ã€å…¸å‹çš„é¢„æœŸ
// - strict (ä¸¥æ ¼): é«˜æ ‡å‡†ã€æ‰¹åˆ¤æ€§è¯„ä¼°

const userPrompt = `ä¸ºä»¥ä¸‹å†…å®¹åˆ›å»ºè¯„åˆ†æ ‡å‡†ï¼š
**æ ‡å‡†åç§°**: ${input.criterionName}
**æ ‡å‡†æè¿°**: ${input.criterionDescription}
**åˆ†åˆ¶**: ${input.scale}
**é¢†åŸŸ**: ${input.domain}

ç”Ÿæˆï¼š
1. æ¯ä¸ªå¾—åˆ†ç­‰çº§çš„æ¸…æ™°æè¿°
2. å®šä¹‰æ¯ä¸ªç­‰çº§çš„å…·ä½“ç‰¹å¾
3. æ¯ä¸ªç­‰çº§çš„ç®€çŸ­ç¤ºä¾‹æ–‡å­—
4. é€šç”¨çš„æ‰“åˆ†æŒ‡å—
5. å¸¦æœ‰æŒ‡å¯¼æ„è§çš„è¾¹ç¼˜æƒ…å†µ`;
```

---

### 4. è¯„ä¼°æ™ºèƒ½ä½“ (Evaluator Agent)

**ç”¨é€”**ï¼šç»“åˆäº†æ‰€æœ‰è¯„ä¼°å·¥å…·åŠå¯¹è¯èƒ½åŠ›çš„é«˜çº§æ™ºèƒ½ä½“ã€‚

**å®ç°**ï¼š

```typescript
export class EvaluatorAgent {
  private model: string;
  private temperature: number;

  constructor(config?: EvaluatorAgentConfig) {
    this.model = config?.model || 'gpt-5.2';
    this.temperature = config?.temperature || 0.3;
  }

  // å¯¹å“åº”è¿›è¡Œè¯„åˆ†
  async score(input: DirectScoreInput) { ... }

  // æ¯”è¾ƒä¸¤ä¸ªå“åº”
  async compare(input: PairwiseCompareInput) { ... }

  // ç”Ÿæˆè¯„åˆ†æ ‡å‡†
  async generateRubric(input: GenerateRubricInput) { ... }

  // å®Œæ•´å·¥ä½œæµï¼šç”Ÿæˆè¯„åˆ†æ ‡å‡†ç„¶åæ‰“åˆ†
  async evaluateWithGeneratedRubric(response, prompt, criteria) { ... }

  // åŸºäºå¯¹è¯çš„è¯„ä¼°
  async chat(userMessage: string) { ... }
}
```

---

## ğŸ“Š æµ‹è¯•ç»“æœ

æ‰€æœ‰ 19 ä¸ªæµ‹è¯•å‡é€šè¿‡ã€‚ä»¥ä¸‹æ˜¯è¿è¡Œæµ‹è¯•çš„å®é™…æ—¥å¿—ï¼š

### æµ‹è¯•è¾“å‡º

```
> readwren-agent-system@1.0.0 test
> vitest run --testTimeout=120000

  RUN  v2.1.9 /Users/muratcankoylan/app_readwren

  âœ“ tests/skills.test.ts (10 tests) 159317ms
    âœ“ LLM Evaluator Skill Tests > Direct Scoring Skill > è¯„åˆ†ä¸­åº”ä½¿ç”¨æ€ç»´é“¾ 4439ms
    âœ“ LLM Evaluator Skill Tests > Direct Scoring Skill > åº”å¤„ç†å¤šä¸ªåŠ æƒæ ‡å‡† 7218ms
    âœ“ LLM Evaluator Skill Tests > Pairwise Comparison Skill > åº”é€šè¿‡äº¤æ¢ä½ç½®ç¼“è§£ä½ç½®åå·® 13002ms
    âœ“ LLM Evaluator Skill Tests > Pairwise Comparison Skill > åº”èƒ½è¯†åˆ«è´¨é‡å·®å¼‚æ˜æ˜¾çš„èƒœå‡ºè€… 25914ms
    âœ“ LLM Evaluator Skill Tests > Rubric Generation Skill > åº”ç”Ÿæˆç‰¹å®šé¢†åŸŸç›¸å…³çš„æ ‡å‡† 37165ms
    âœ“ LLM Evaluator Skill Tests > Rubric Generation Skill > åº”æä¾›é’ˆå¯¹è¾¹ç¼˜æƒ…å†µçš„æŒ‡å¯¼ 29088ms
    âœ“ LLM Evaluator Skill Tests > Context Fundamentals Skill Application > è¯„ä¼°ä¸­åº”åˆ©ç”¨æä¾›çš„èƒŒæ™¯ä¿¡æ¯ 11133ms

  âœ“ tests/evaluation.test.ts (9 tests) 216353ms
    âœ“ Direct Score Tool > åº”æ ¹æ®æ ‡å‡†å¯¹å“åº”è¿›è¡Œè¯„åˆ† 13219ms
    âœ“ Pairwise Compare Tool > åº”æ­£ç¡®è¯†åˆ«è¡¨ç°æ›´ä¼˜çš„å“åº” 29254ms
    âœ“ Generate Rubric Tool > åº”ç”Ÿæˆå®Œæ•´çš„è¯„åˆ†æ ‡å‡† 24106ms
    âœ“ Evaluator Agent > åº”æä¾›é›†æˆçš„è¯„ä¼°å·¥ä½œæµ 48112ms

  Test Files  2 passed (2)
       Tests  19 passed (19)
    Start at  00:25:16
    Duration  216.66s
```

---

## ğŸ“š å…³é”®æ”¶è·

1. **ä½ç½®åå·®å®¢è§‚å­˜åœ¨**ï¼šæµ‹è¯•ç¡®è®¤äº†å³ä½¿æ˜¯é«˜è´¨é‡æ¨¡å‹ä¹Ÿä¼šå—å“åº”é¡ºåºå½±å“ã€‚äº¤æ¢ä½ç½®èƒ½æ˜¾è‘—æé«˜è¯„ä¼°çš„å¯é æ€§ã€‚
2. **æ€ç»´é“¾èƒ½æå‡è´¨é‡**ï¼šå¼ºåˆ¶è¦æ±‚æ¨¡å‹å…ˆæä¾›ç†ç”±å†æ‰“åˆ†ï¼Œèƒ½å‡å°‘éšæ„æ€§ï¼Œä½¿è¯„åˆ†æ›´æœ‰æ®å¯æŸ¥ã€‚
3. **ç‰¹å®šé¢†åŸŸçš„è¯„åˆ†æ ‡å‡†è‡³å…³é‡è¦**ï¼šä¾‹å¦‚ï¼Œè½¯ä»¶å·¥ç¨‹çš„è¯„åˆ†æ ‡å‡†å¿…é¡»åŒ…å«â€œä»£ç è§„èŒƒâ€ã€â€œæ–‡æ¡£â€ç­‰æœ¯è¯­æ‰æ›´æœ‰é’ˆå¯¹æ€§ã€‚
4. **åŠ æƒæ ‡å‡†æ”¯æŒæ›´ç»†è…»çš„è¯„ä¼°**ï¼šåœ¨æŸäº›åœºæ™¯ä¸‹ï¼Œâ€œå‡†ç¡®æ€§â€å¯èƒ½æ¯”â€œå¯è¯»æ€§â€æƒé‡æ›´é«˜ï¼ŒåŠ æƒæ‰“åˆ†èƒ½åæ˜ è¿™ä¸€ç‚¹ã€‚

---

## ğŸš€ å¿«é€Ÿä¸Šæ‰‹

### å®‰è£…

```bash
git clone https://github.com/muratcankoylan/llm-as-judge-skills.git
cd llm-as-judge-skills
npm install
```

### é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-5.2  
```

### è¿è¡Œæµ‹è¯•

```bash
npm test
```

### åŸºç¡€ç”¨æ³•

```typescript
import { EvaluatorAgent } from './src/agents/evaluator';

const agent = new EvaluatorAgent();

// å¯¹å“åº”è¿›è¡Œè¯„åˆ†
const scoreResult = await agent.score({
  response: 'æ‚¨çš„ AI ç”Ÿæˆå“åº”',
  prompt: 'åŸå§‹æç¤ºè¯',
  criteria: [
    { name: 'Accuracy', description: 'äº‹å®å‡†ç¡®åº¦', weight: 1 }
  ]
});

console.log(`å¾—åˆ†: ${scoreResult.overallScore}/5`);
```

---

## ğŸ”— ä¸ Agent Skills ä»“åº“çš„é›†æˆ

æ­¤é¡¹ç›®è¢«è®¾è®¡ä¸ºæ·»åŠ åˆ°ä¸»ä»“åº“çš„ç¤ºä¾‹éƒ¨åˆ†ï¼š

```
Agent-Skills-for-Context-Engineering/
â”œâ”€â”€ skills/
â”‚   â”œâ”€â”€ context-fundamentals/     # åŸºç¡€ï¼ˆæœ¬é¡¹ç›®å¼•ç”¨ï¼‰
â”‚   â””â”€â”€ tool-design/              # åŸºç¡€ï¼ˆæœ¬é¡¹ç›®å¼•ç”¨ï¼‰
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ llm-as-judge-skills/      # â† æœ¬é¡¹ç›®
â”‚       â”œâ”€â”€ README_zh.md
â”‚       â”œâ”€â”€ skills/
â”‚       â”œâ”€â”€ tools/
â”‚       â”œâ”€â”€ agents/
â”‚       â””â”€â”€ src/
```

---

## ğŸ“‹ API å‚è€ƒ

### DirectScoreInput (ç›´æ¥è¯„åˆ†è¾“å…¥)

```typescript
interface DirectScoreInput {
  response: string;              // å¾…è¯„ä¼°çš„å“åº”
  prompt: string;                // åŸå§‹æç¤ºè¯
  context?: string;              // é¢å¤–èƒŒæ™¯ä¿¡æ¯
  criteria: Array<{
    name: string;                // æ ‡å‡†åç§°
    description: string;         // è¡¡é‡ä»€ä¹ˆ
    weight: number;              // ç›¸å¯¹é‡è¦æ€§ (0-1)
  }>;
  rubric?: {
    scale: '1-3' | '1-5' | '1-10';
    levelDescriptions?: Record<string, string>;
  };
}
```

---

## ğŸ“„ è®¸å¯è¯

MIT è®¸å¯è¯ - è¯¦æƒ…è¯·å‚é˜… [LICENSE](LICENSE) æ–‡ä»¶ã€‚
