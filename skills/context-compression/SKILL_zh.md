---
name: context-compression
description: 当用户要求“压缩上下文”、“总结对话历史记录”、“实现压实（compaction）”、“减少 token 使用”，或提到上下文压缩、结构化摘要、单任务 token 优化或长周期助手会话超出上下文限制时，应使用此技巧。
---

# 上下文压缩策略 (Context Compression Strategies)

当助手会话产生数百万 token 的对话历史时，压缩变得必不可少。平庸的方法是强力压缩以最小化单次请求的 token 数。正确的优化目标应该是**“单任务 token 数（tokens-per-task）”**：即完成任务所消耗的总 token 数，包括由于压缩丢失关键信息而导致的重新检索（re-fetching）成本。

## 何时激活

在以下情况下启用此技能：
- 助手会话超出上下文窗口限制
- 代码库大小超出上下文窗口（500 万+ token 的系统）
- 设计对话摘要策略
- 调试助手“忘记”修改了哪些文件的情况
- 构建压缩质量评估框架

## 核心概念

上下文压缩在 token 节省与信息丢失之间进行权衡。目前有三种生产级的方案：

1.  **锚定迭代摘要 (Anchored Iterative Summarization)**：维护一个结构化的、持久的摘要，包含显式的分区（会话意图、文件修改、决策、下一步）。触发压缩时，仅对新截断的部分进行摘要并合并到现有摘要中。
2.  **不透明压缩 (Opaque Compression)**：产生高度压缩的表示。虽然压缩率极高（99%+），但牺牲了可读性，无法验证保留了什么。
3.  **全量再生摘要 (Regenerative Full Summary)**：每次压缩时生成详细的结构化摘要。可读性好，但在多次循环中容易丢失细节。

**核心洞察**：**结构强制保留**。专门的分区充当了摘要器必须填充的检查清单，防止信息的无声流失。

## 详细主题

### 为什么单任务 Token 数很重要
如果压缩丢失了文件路径或错误消息，助手就必须重新检索信息、重新探索路径，从而在恢复上下文上浪费 token。节省 0.5% 的 token 但导致 20% 的重新检索成本，在总体上是亏损的。

### 制品链 (Artifact Trail) 问题
在评估中，“制品链完整性”是所有压缩方法中最薄弱的维度（2.2-2.5 分/5.0 分）。编程助手需要知道：
- 创建/修改/读取了哪些文件
- 具体的变更内容
- 函数名、变量名、错误消息

这可能需要摘要之外的专门处理：独立的制品索引或助手支架中的显式文件状态追踪。

### 结构化摘要分区示例
```markdown
## 会话意图
[用户想要实现的目标]

## 已修改文件
- auth.controller.ts: 修复了 JWT 生成
- config/redis.ts: 更新了连接池

## 已做决策
- 使用 Redis 连接池而非单次连接
- 针对瞬时故障实现指数退避重试

## 下一步
1. 修复剩余测试失败
2. 运行完整测试套件
```

### 压缩触发策略
- **固定阈值**：上下文利用率达到 70-80% 时。
- **滑动窗口**：保留最后 N 轮 + 摘要。
- **基于重要性**：优先压缩低相关性部分。

## 实践指南

### 三阶段压缩工作流 (针对大型代码库)
1.  **研究阶段**：将复杂的探索压缩成的结构化分析文档（组件与依赖）。
2.  **规划阶段**：将研究转化为包含函数签名、数据流的实施规范。
3.  **实施阶段**：针对规范执行，上下文保持对规范的关注。

### 什么时候使用哪种方法
- **锚定迭代摘要**：会话长（100+ 消息）、文件追踪很重要、需要验证保留内容。
- **不透明压缩**：需要极致的 token 节省、会话短、重读成本低。
- **全量再生摘要**：摘要的可读性至关重要、任务有明显的阶段界限。

## Guidelines

1. 优化单任务 token 数，而非单次请求 token 数。
2. 使用带有显式文件追踪分区的结构化摘要。
3. 在利用率达到 70-80% 时触发压缩。
4. 实施增量合并（merging）而非全量再生（regeneration）。
5. 使用基于探测（probe-based）的评估来测试压缩质量。
6. 如果文件追踪极其关键，请单独追踪制品链。
7. 接受稍低的压缩率以换取更好的质量保留。

## 技巧元数据

**创建日期**: 2025-12-22
**作者**: Agent Skills for Context Engineering 贡献者
**版本**: 1.1.0
