---
name: evaluation
description: 当用户要求“评估智能体性能”、“构建测试框架”、“衡量智能体质量”、“创建评估评分表”，或提到 LLM-as-judge、多维度评估、智能体测试或智能体流水线的质量关卡时，应使用此技能。
---

# 智能体系统的评估方法

评估智能体系统需要采用与传统软件甚至标准语言模型应用不同的方法。智能体做出动态决策，在不同运行之间具有非确定性，并且通常缺乏单一的标准答案。有效的评估必须在说明这些特性的同时，提供可操作的反馈。一个稳健的评估框架能够支持持续改进、捕获性能回退，并验证上下文工程的选择是否达到了预期效果。

## 何时激活

当出现以下情况时激活此技能：
- 系统地测试智能体性能。
- 验证上下文工程的选择。
- 衡量随时间推移的改进。
- 在部署前捕获性能回退（Regressions）。
- 为智能体流水线（Pipelines）建立质量关卡（Quality gates）。
- 比较不同的智能体配置。
- 持续评价生产环境系统。

## 核心概念

智能体评估需要以**结果为导向**的方法，这些方法要考虑到非确定性和多条有效路径。**多维度评分表（Rubrics）**能够捕捉各个维度的质量：事实准确性、完整性、引用准确性、来源质量和工具效率。**LLM-as-judge**（以大模型作为裁判）提供了可扩展的评估，而**人工评估**则负责捕获边缘情况。

关键见解在于：智能体可能会找到达成目标的替代路径——评估应该判断它们是否在遵循合理过程的同时实现了正确的结果。

**性能驱动因素：95% 发现**
关于 BrowseComp 评估（测试浏览智能体定位难以找到的信息的能力）的研究发现，三个因素解释了 95% 的性能差异：

| 因素 | 解释的方差 | 启示 |
|--------|-------------------|-------------|
| Token 使用量 | 80% | 更多的 Token = 更好的性能 |
| 工具调用次数 | ~10% | 更多的探索有助于提升性能 |
| 模型选择 | ~5% | 更好的模型会成倍提高效率 |

这一发现对评估设计具有重大意义：
- **Token 预算至关重要**：在现实的 Token 预算下评估智能体，而不是无限资源。
- **模型升级优于 Token 增加**：升级到 Claude Sonnet 4.5 或 GPT-5.2 比在旧版本上增加一倍 Token 预算带来的收益更大。
- **多智能体验证**：该发现验证了将工作分配给具有独立上下文窗口的多个智能体的架构。

## 详细主题

### 评估挑战

**非确定性与多条有效路径**
智能体可能会采取完全不同的有效路径来达成目标。一个智能体可能搜索三个来源，而另一个搜索十个。它们可能使用不同的工具找到相同的答案。在这种情况下，检查特定步骤的传统评估方法会失败。

解决方案是**以结果为导向的评估**，判断智能体是否在遵循合理过程的同时实现了正确的结果。

**上下文相关的失败**
智能体的失败通常以微妙的方式依赖于上下文。一个智能体可能在简单查询上成功，但在复杂查询上失败。它可能在一套工具集中表现良好，但在另一套中失败。失败可能只在上下文累积的长时间交互后才出现。

评估必须覆盖一系列复杂度等级，并测试长时间交互，而不仅仅是孤立的查询。

**综合质量维度**
智能体的质量不是单一维度的。它包括事实准确性、完整性、连贯性、工具效率和过程质量。一个智能体可能在准确性上得分很高，但在效率上得分很低，反之亦然。

评估评分表（Rubrics）必须捕获多个维度，并根据使用场景进行适当加权。

### 评估评分表（Rubrics）设计

**多维度评分表**
有效的评分表应涵盖关键维度并提供描述性的等级：

- 事实准确性：声明与事实真相（Ground Truth）相符（从优秀到失败）。
- 完整性：输出涵盖了要求的各个方面（从优秀到失败）。
- 引用准确性：引用与声称的来源相符（从优秀到失败）。
- 来源质量：使用了适当的一手来源（从优秀到失败）。
- 工具效率：在合理的次数内使用了正确的工具（从优秀到失败）。

**评分方法**
将各维度的评估转化为数值分数（0.0 到 1.0），并进行相应加权。计算加权后的总分。根据使用场景的要求确定通过阈值。

### 评估方法学

**LLM-as-Judge**
基于大模型的评估可以扩展到大型测试集，并提供一致的判定。关键在于设计有效的评估提示词，以捕捉感兴趣的维度。

提供清晰的任务描述、智能体输出、事实真相（如有）、带有等级描述的评估量表，并请求结构化的判定结果。

**人工评估**
人工评估可以捕获自动化评估遗漏的内容。人类能够注意到非常规查询中的幻觉答案、系统故障以及自动化评估可能错过的微妙偏见。

有效的人工评估应覆盖边缘情况、进行系统采样、跟踪模式并提供背景理解。

**终态评估 (End-State Evaluation)**
对于修改持久状态的智能体，终态评估关注最终状态是否符合预期，而不是智能体是如何到达那里的。

### 测试集设计

**样本选择**
在开发初期从较小的样本开始。在智能体开发早期，由于存在大量“低垂的果实”（容易改进的地方），微小的变动都会产生巨大影响。小型测试集足以揭示显著效果。

从真实的调用模式中采样。添加已知的边缘情况。确保覆盖不同的复杂度等级。

**复杂度分层**
测试集应跨越不同的复杂度等级：简单（单次工具调用）、中等（多次工具调用）、复杂（多次工具调用，存在显著歧义）和极复杂（长时间交互，深度推理）。

### 上下文工程评估

**测试上下文策略**
上下文工程的选择应通过系统评估来验证。在相同的测试集上运行具有不同上下文策略的智能体。比较质量分数、Token 使用量和效率指标。

**回退测试 (Degradation Testing)**
通过在不同的上下文大小下运行智能体，测试上下文退化如何影响性能。识判定上下文变得成问题的“性能悬崖”。建立安全的操作限制。

### 持续评估

**评估流水线**
建立在智能体变更时自动运行的评估流水线。跟踪随时间推移的结果。比较不同版本以识别改进或回退。

**生产环境监控**
通过对交互进行采样并随机评估，在生产环境中跟踪评估指标。为质量下降设置告警。维护仪表板进行趋势分析。

## 实践指南

### 构建评估框架

1. 定义与你的使用场景相关的质量维度。
2. 创建具有清晰、可操作等级描述的评分表。
3. 从真实使用模式和边缘情况中构建测试集。
4. 实现自动化的评估流水线。
5. 在做出更改前建立基准指标。
6. 对所有重大更改运行评估。
7. 跟踪指标以进行趋势分析。
8. 用人工审核补充自动化评估。

### 避免评估陷阱

- **过度拟合特定路径**：评估结果，而非特定步骤。
- **忽视边缘情况**：包含多样的测试场景。
- **单一指标痴迷**：使用多维度评分表。
- **忽视上下文效应**：在现实的上下文大小下进行测试。
- **跳过人工评估**：自动化评估会错过微妙的问题。

## 示例

**示例 1：简单的评估逻辑**
```python
def evaluate_agent_response(response, expected):
    rubric = load_rubric()
    scores = {}
    for dimension, config in rubric.items():
        scores[dimension] = assess_dimension(response, expected, dimension)
    overall = weighted_average(scores, config["weights"])
    return {"passed": overall >= 0.7, "scores": scores}
```

**示例 2：测试集结构**
测试集应涵盖多个复杂度等级以确保全面评估：

```python
test_set = [
    {
        "name": "simple_lookup",
        "input": "法国的首都是哪里？",
        "expected": {"type": "fact", "answer": "巴黎"},
        "complexity": "simple",
        "description": "单次工具调用，事实查找"
    },
    {
        "name": "medium_query",
        "input": "比较苹果和微软上个季度的营收",
        "complexity": "medium",
        "description": "多次工具调用，比较逻辑"
    },
    {
        "name": "multi_step_reasoning",
        "input": "分析 Q1-Q4 的销售数据并创建包含趋势的总结报告",
        "complexity": "complex",
        "description": "多次工具调用，聚合，分析"
    },
    {
        "name": "research_synthesis",
        "input": "研究新兴 AI 技术，评估其潜在影响，并推荐采用策略",
        "complexity": "very_complex",
        "description": "长时间交互，深度推理，综合"
    }
]
```

## 指南

1. 使用多维度评分表，而非单一指标。
2. 评估结果，而非特定的执行路径。
3. 覆盖从简单到复杂的各个复杂度等级。
4. 在现实的上下文大小和历史记录下进行测试。
5. 持续运行评估，而不仅仅是在发布前。
6. 用人工审核补充 LLM 评估。
7. 跟踪随时间变化的指标以检测趋势。
8. 根据使用场景设定清晰的通过/失败阈值。

## 集成

此技能作为一个横向关注点连接到所有其他技能：
- context-fundamentals：评估上下文使用情况。
- context-degradation：检测性能退化。
- context-optimization：衡量优化有效性。
- multi-agent-patterns：评估协作性。
- tool-design：评估工具的有效性。
- memory-systems：评估记忆质量。

---

## 技能元数据

**创建日期**：2025-12-20
**上次更新**：2025-12-20
**作者**：上下文工程智能体技能贡献者
**版本**：1.0.0
