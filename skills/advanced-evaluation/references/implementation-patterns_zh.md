# LLM 裁判实现模式 (LLM-as-Judge Implementation Patterns)

本参考文档提供构建生产级 LLM 评估系统的详细实现模式。

## 模式 1：结构化评估流水线 (Structured Evaluation Pipeline)

最可靠的评估系统遵循关注点分离的流水线：
`输入验证 → 标准加载 → 评分 → 偏差缓解 → 输出格式化`

- **输入验证层**：在开始评估前，验证响应、提示词是否存在，标准是否有效，以及权重是否归一化。
- **标准加载层**：标准应通过配置文件加载，而非硬编码。
- **评分层**：处理实际的 LLM 调用。建议将 `temperature` 设置为较小值（如 0.3）以保证一致性。
- **偏差缓解层**：对于成对比较，必须包含“交换位置（position swapping）”逻辑，并检查两次评估结论的一致性。

## 模式 2：分层评估 (Hierarchical Evaluation)

针对复杂评估任务，采用分层方案：
`快速筛选（廉价模型）→ 详细评估（昂贵模型）→ 人工审核（边缘案例）`

- **快速筛选**：使用如 GPT-5.2 等廉价模型，判断是否明显通过或失败。
- **详细评估**：针对处于边界线或极其重要的案例，使用能力更强的模型进行细分维度的打分。

## 模式 3：LLM 裁判团 (Panel of LLM Judges - PoLL)

针对高风险评估（High-stakes evaluation），同时调用多个不同厂商、不同架构的模型进行打分。
- 使用**中位数**聚合得分以抵抗离群值（outliers）。
- 计算模型间的一致性（agreement rate）作为置信度指标。

## 模式 4：置信度校准 (Confidence Calibration)

置信度得分应根据多种信号进行校准，而非仅听信模型的自述：
- **位置一致性**：如果交换位置后结论相反，置信度应大幅折减。
- **证据强度**：理由中提及的证据点（evidence count）越多，置信度越高。
- **上限限制**：置信度永远不应设为 100%。

## 模式 5：输出格式化 (Output Formatting)

始终返回结构化的响应（使用 JSON 或 Pydantic/Dataclass），包含：
- 每个维度的评分及对应的理由、证据、改进建议。
- 整体得分和加权总分。
- 汇总元数据。

## 故障处理与重试模式

- **优雅降级**：如果全量评估因频率限制报错，回退到简版评估。
- **重试逻辑**：针对瞬时错误（TransientError），使用指数退避（Exponential backoff）进行重试。

## 测试模式

- **解析逻辑单元测试**：确保能正确解析 JSON，并能处理格式不规范的输出。
- **集成测试**：使用真实事实测试其打分的准确性。
- **偏见检测测试**：例如将两个完全相同的响应进行比较，结果应为 TIE（平局）。
